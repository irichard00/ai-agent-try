# LLM Configuration
LLM_DEFAULT_BASE_URL=http://your-llm-server-url
LLM_DEFAULT_APIKEY=your-llm-api-key
LLM_DEFAULT_MODEL=gpt-4.1

# OpenAI Configuration (for genie-tool)
OPENAI_API_KEY=your-openai-api-key
OPENAI_BASE_URL=https://api.openai.com/v1

# MCP Configuration
MCP_SERVER_URL=https://mcp.api-inference.modelscope.net/1784ac5c6d0044/sse

# Service Ports (optional - defaults are set)
UI_PORT=3000
BACKEND_PORT=8080
TOOL_PORT=1601
CLIENT_PORT=8188

# Environment (development/production)
NODE_ENV=production
DEBUG_MODE=false